# -*- coding: utf-8 -*-
"""Untitled98.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rr5nqx80y3GvgLOkuWT7IQbP82Lu1DOS
"""

import numpy as np

class NaiveBayesClassifier:
    def __init__(self):
        self.classes = None
        self.class_priors = None
        self.feature_probs = None

    def train(self, X, y):
        self.classes = np.unique(y)
        num_classes = len(self.classes)
        num_features = X.shape[1]

        # Calculate class priors
        self.class_priors = np.zeros(num_classes)
        for i, c in enumerate(self.classes):
            self.class_priors[i] = np.sum(y == c) / len(y)

        # Calculate feature probabilities
        self.feature_probs = np.zeros((num_classes, num_features))
        for i, c in enumerate(self.classes):
            X_c = X[y == c]
            self.feature_probs[i] = (np.sum(X_c, axis=0) + 1) / (np.sum(X_c) + num_features)

    def predict(self, X):
        num_instances = X.shape[0]
        num_classes = len(self.classes)

        # Calculate the log likelihood of each instance for each class
        log_likelihoods = np.zeros((num_instances, num_classes))
        for i in range(num_instances):
            for j in range(num_classes):
                log_likelihoods[i, j] = np.sum(np.log(self.feature_probs[j]) * X[i] +
                                              np.log(1 - self.feature_probs[j]) * (1 - X[i]))

        # Calculate the log posterior probability of each instance for each class
        log_posteriors = log_likelihoods + np.log(self.class_priors)

        # Predict the class with the highest log posterior probability
        predictions = np.argmax(log_posteriors, axis=1)
        predicted_classes = self.classes[predictions]

        return predicted_classes